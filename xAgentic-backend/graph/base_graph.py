"""
åŸºç¡€å›¾ç±» - æå–å…¬å…±æ–¹æ³•å’ŒåŠŸèƒ½

åŒ…å«æ‰€æœ‰å›¾ç±»çš„å…¬å…±æ–¹æ³•ï¼Œé¿å…ä»£ç é‡å¤
"""
import time
from datetime import datetime
from typing import List, TypedDict, AsyncIterator

from langchain_core.messages.base import BaseMessage
from langgraph.checkpoint.memory import MemorySaver

from services.service_manager import service_manager
from tools.code_tools import *
from tools.search_tools import *
from tools.time_tools import *
from utils.custom_serializer import CustomSerializer
from utils.unified_logger import get_logger


class BaseGraphState(TypedDict):
    """åŸºç¡€å›¾çŠ¶æ€ - åŒ…å«æ‰€æœ‰å›¾ç±»çš„å…¬å…±çŠ¶æ€å­—æ®µ"""
    # æ¶ˆæ¯å’Œé€šä¿¡
    messages: List[BaseMessage]
    streaming_chunks: List[Dict[str, Any]]
    
    # çŠ¶æ€ç®¡ç†
    status: str
    error: str
    
    # ä¸Šä¸‹æ–‡ä¿¡æ¯
    thread_id: str
    
    # å…ƒæ•°æ®
    timing_info: Dict[str, Any]


class BaseGraph:
    """åŸºç¡€å›¾ç±» - æä¾›æ‰€æœ‰å›¾ç±»çš„å…¬å…±åŠŸèƒ½"""
    
    def __init__(self, graph_name: str):
        """åˆå§‹åŒ–åŸºç¡€å›¾ç±»"""
        self.thread_id = None
        self.logger = get_logger(__name__)
        self.graph_name = graph_name
        
        # ä½¿ç”¨å…¨å±€æœåŠ¡ç®¡ç†å™¨ä¸­çš„é…ç½®å’ŒLLMå®ä¾‹
        self.config = service_manager.get_config()
        llms = service_manager.get_llms()
        self.strategic_llm = llms.get('strategic_llm')
        self.fast_llm = llms.get('fast_llm')
        self.vision_llm = llms.get('vision_llm')
        
        # è·å–å·¥å…·
        self.mcp_tools = service_manager.get_mcp_tools()
        self.local_tools = [
            web_search, execute_python_code, get_current_time,
            calculate_date_offset, get_time_info
        ]
        self.all_tools = self.local_tools + self.mcp_tools
        
        self.store = service_manager.store
    
    def _initialize_checkpointer(self, graph_class):
        """åˆå§‹åŒ–æ£€æŸ¥ç‚¹å­˜å‚¨ - å…¬å…±æ–¹æ³•"""
        if not hasattr(graph_class, '_initialized') or not graph_class._initialized:
            # åˆå§‹åŒ–LangGraphæ£€æŸ¥ç‚¹å­˜å‚¨
            custom_serializer = CustomSerializer()
            graph_class._shared_checkpointer = MemorySaver(serde=custom_serializer)
            graph_class._initialized = True
            self.logger.info(f"{self.graph_name} é¦–æ¬¡åˆå§‹åŒ–å®Œæˆ")
    
    def _add_streaming_chunk(self, state: Dict[str, Any], step: str, message: str,
                             data: Dict[str, Any] = None) -> None:
        """æ·»åŠ æµå¼è¾“å‡ºå—çš„è¾…åŠ©æ–¹æ³• - å…¬å…±æ–¹æ³•"""
        if "streaming_chunks" not in state:
            state["streaming_chunks"] = []
        
        chunk = {
            "step": step,
            "message": message
        }
        if data:
            chunk["data"] = data
        state["streaming_chunks"].append(chunk)
    
    def _extract_execution_result(self, result, node_description: str = ""):
        """æå–æ‰§è¡Œç»“æœ - å…¬å…±æ–¹æ³•"""
        execution_result = ""
        try:
            if result and isinstance(result, dict):
                if "messages" in result:
                    messages = result["messages"]
                    if messages:
                        # æŸ¥æ‰¾æœ€åä¸€ä¸ªAIæ¶ˆæ¯
                        for msg in reversed(messages):
                            if hasattr(msg, 'content'):
                                msg_type = str(type(msg)).lower()
                                if 'ai' in msg_type or 'assistant' in msg_type:
                                    execution_result = msg.content
                                    break
                        else:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°AIæ¶ˆæ¯ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªæ¶ˆæ¯
                            last_message = messages[-1]
                            if hasattr(last_message, 'content'):
                                execution_result = last_message.content
                            else:
                                execution_result = str(last_message)
                elif "output" in result:
                    execution_result = str(result["output"])
                else:
                    execution_result = str(result)
            elif result and hasattr(result, 'content'):
                # å¦‚æœresultç›´æ¥æ˜¯æ¶ˆæ¯å¯¹è±¡ï¼ˆç›´æ¥LLMè°ƒç”¨ï¼‰
                execution_result = result.content
            elif result:
                # å…¶ä»–æƒ…å†µï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                execution_result = str(result)
            
            # å¦‚æœç»“æœå¤ªçŸ­æˆ–åŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œæä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯
            if len(execution_result) < 10 or "sorry" in execution_result.lower():
                execution_result = f"ä»»åŠ¡æè¿°: {node_description}\næ‰§è¡ŒçŠ¶æ€: å·²å®Œæˆ\nç»“æœ: {execution_result}"
                
        except Exception as e:
            self.logger.error(f"æå–æ‰§è¡Œç»“æœæ—¶å‡ºé”™: {str(e)}")
            execution_result = f"æ‰§è¡Œå®Œæˆï¼Œä½†ç»“æœæå–æ—¶å‡ºç°é”™è¯¯: {str(e)}"
        
        return execution_result
    
    def _get_timing_info(self, start_time: float, operation_name: str) -> Dict[str, Any]:
        """è·å–æ—¶é—´ä¿¡æ¯ - å…¬å…±æ–¹æ³•"""
        duration = time.time() - start_time
        return {
            f"{operation_name}_duration": round(duration, 2),
            f"{operation_name}_timestamp": datetime.now().isoformat()
        }
    
    async def process_streaming_events(self, events: AsyncIterator[Dict[str, Any]]) -> AsyncIterator[Dict[str, Any]]:
        """å¤„ç†æµå¼äº‹ä»¶çš„å…¬å…±æ–¹æ³•"""
        try:
            async for event in events:
                self.logger.info(f"æ”¶åˆ°event: {event['event']} - {event.get('name', 'unknown')}")
                
                if event["event"] == "on_chain_stream":
                    chunk = event.get("data", {}).get("chunk", {})
                    if isinstance(chunk, dict) and "streaming_chunks" in chunk:
                        for streaming_chunk in chunk["streaming_chunks"]:
                            yield {
                                "step": streaming_chunk.get("step"),
                                "message": streaming_chunk.get("message"),
                                "data": streaming_chunk.get("data"),
                                "node": event.get("name", "unknown")
                            }
                    if isinstance(chunk, dict) and "__interrupt__" in chunk:
                        chunk_interrupt = chunk["__interrupt__"][0]
                        yield {
                            "step": "interrupt",
                            "message": "éœ€è¦ç”¨æˆ·ç¡®è®¤",
                            "data": chunk_interrupt.value,
                            "node": "check_node_uncertainty"
                        }
                        return
                elif event["event"] == "on_chain_start":
                    # æ™ºèƒ½ä½“å¼€å§‹æ‰§è¡Œ
                    yield {
                        "step": "agent_start",
                        "message": f"ğŸš€ å¼€å§‹æ‰§è¡Œ {event.get('name', 'æ™ºèƒ½ä½“')}",
                        "data": {
                            "agent": event.get("name", "unknown")
                        },
                        "node": event.get("name", "unknown")
                    }
                elif event["event"] == "on_chain_end":
                    # æ™ºèƒ½ä½“æ‰§è¡Œå®Œæˆ
                    yield {
                        "step": "agent_complete",
                        "message": f"âœ… {event.get('name', 'æ™ºèƒ½ä½“')} æ‰§è¡Œå®Œæˆ",
                        "data": {
                            "agent": event.get("name", "unknown")
                        },
                        "node": event.get("name", "unknown")
                    }
                elif event["event"] == "on_tool_start":
                    # å·¥å…·å¼€å§‹æ‰§è¡Œ
                    yield {
                        "step": "tool_start",
                        "message": f"ğŸ”§ ä½¿ç”¨å·¥å…·: {event.get('name', 'unknown')}",
                        "data": {
                            "tool": event.get("name", "unknown")
                        },
                        "node": "tool_execution"
                    }
                elif event["event"] == "on_tool_end":
                    # å·¥å…·æ‰§è¡Œå®Œæˆ
                    yield {
                        "step": "tool_complete",
                        "message": f"âœ… å·¥å…· {event.get('name', 'unknown')} æ‰§è¡Œå®Œæˆ",
                        "data": {
                            "tool": event.get("name", "unknown")
                        },
                        "node": "tool_execution"
                    }
        except Exception as e:
            self.logger.error(f"æµå¼å¤„ç†å¤±è´¥: {str(e)}")
            yield {
                "step": "error",
                "message": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
                "data": {},
                "node": "error"
            }
    
    
    def _format_tools_list(self, tools: List) -> List[str]:
        """æ ¼å¼åŒ–å·¥å…·åˆ—è¡¨ - å…¬å…±æ–¹æ³•"""
        tools_list = []
        for t in tools:
            if hasattr(t, 'name') and hasattr(t, 'description'):
                tools_list.append(f"- {t.name}: {t.description}")
            else:
                tools_list.append(f"- {t.__name__ if hasattr(t, '__name__') else str(t)}")
        return tools_list
