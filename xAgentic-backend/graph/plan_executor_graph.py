"""
å¾ªç¯å¼è§„åˆ’æ‰§è¡Œå™¨ - æ¯ä¸ªèŠ‚ç‚¹å…ˆæ£€æŸ¥ä¸ç¡®å®šæ€§ï¼Œç¡®è®¤åæ‰§è¡Œ

æ‰§è¡Œæµç¨‹ï¼š
1. åˆ¶å®šè®¡åˆ’
2. å¾ªç¯æ‰§è¡Œï¼šæ£€æŸ¥èŠ‚ç‚¹ä¸ç¡®å®šæ€§ â†’ ç¡®è®¤ï¼ˆå¦‚éœ€è¦ï¼‰â†’ æ‰§è¡ŒèŠ‚ç‚¹
3. ç”Ÿæˆæœ€ç»ˆå›å¤
"""
import time
from datetime import datetime
from typing import List, AsyncIterator

from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.graph.state import CompiledStateGraph
from langgraph.prebuilt import create_react_agent
from langgraph.types import interrupt
from langmem import create_manage_memory_tool, create_search_memory_tool

from graph.base_graph import BaseGraph, BaseGraphState
from prompt.plan_executor_prompts import *
from tools.code_tools import *
from utils import json_utils
from utils.unified_logger import log_error


class PlanExecutorState(BaseGraphState):
    """å¾ªç¯å¼è§„åˆ’æ‰§è¡ŒçŠ¶æ€"""
    # ä»»åŠ¡æ‰§è¡Œ
    user_task: str
    task_analysis: str
    execution_plan: List[Dict[str, Any]]
    current_step: int
    step_results: List[Dict[str, Any]]


class PlanExecutorGraph(BaseGraph):
    """å¾ªç¯å¼è§„åˆ’æ‰§è¡Œå™¨ - æ¯ä¸ªèŠ‚ç‚¹å…ˆæ£€æŸ¥ä¸ç¡®å®šæ€§ï¼Œç¡®è®¤åæ‰§è¡Œ"""

    # ç±»çº§åˆ«çš„å›¾å®ä¾‹å’Œæ£€æŸ¥ç‚¹å­˜å‚¨ï¼Œç¡®ä¿æ‰€æœ‰å®ä¾‹å…±äº«ç›¸åŒçš„çŠ¶æ€
    _shared_checkpointer = None
    _shared_graph = None
    _initialized = False

    def __init__(self):
        super().__init__("PlanExecutorGraph")
        
        # ä½¿ç”¨å…±äº«çš„å›¾å®ä¾‹å’Œæ£€æŸ¥ç‚¹å­˜å‚¨
        if not PlanExecutorGraph._initialized:
            # åˆå§‹åŒ–æ£€æŸ¥ç‚¹å­˜å‚¨
            self._initialize_checkpointer(PlanExecutorGraph)
            
            # æ„å»ºå›¾
            PlanExecutorGraph._shared_graph = self._build_graph()
            PlanExecutorGraph._initialized = True

        # ä½¿ç”¨å…±äº«çš„å›¾å®ä¾‹
        self.graph = PlanExecutorGraph._shared_graph
        self.checkpointer = PlanExecutorGraph._shared_checkpointer
        self.logger.info("PlanExecutorGraph å®ä¾‹åˆ›å»ºå®Œæˆ")

    def _build_graph(self) -> CompiledStateGraph:
        """æ„å»ºå¾ªç¯å¼æ‰§è¡Œå›¾ - æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œå‰éƒ½æ£€æŸ¥ä¸ç¡®å®šæ€§"""
        workflow = StateGraph(PlanExecutorState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("analyze_and_plan", self._analyze_and_plan)
        workflow.add_node("check_and_execute_node", self._check_and_execute_node)
        workflow.add_node("generate_response", self._generate_response)

        # è®¾ç½®æµç¨‹
        workflow.set_entry_point("analyze_and_plan")
        workflow.add_edge("analyze_and_plan", "check_and_execute_node")

        # æ£€æŸ¥å¹¶æ‰§è¡ŒèŠ‚ç‚¹åçš„æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "check_and_execute_node",
            self._after_check_and_execute,
            {
                "next_node": "check_and_execute_node",  # ç»§ç»­æ£€æŸ¥ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                "complete": "generate_response"  # æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ
            }
        )

        workflow.add_edge("generate_response", END)

        return workflow.compile(checkpointer=PlanExecutorGraph._shared_checkpointer)

    def _analyze_and_plan(self, state: PlanExecutorState) -> PlanExecutorState:
        """ä»»åŠ¡åˆ†æå’Œè®¡åˆ’åˆ›å»ºèŠ‚ç‚¹"""
        try:
            self.logger.info("å¼€å§‹ä»»åŠ¡åˆ†æå’Œè®¡åˆ’åˆ›å»º")
            if "streaming_chunks" not in state:
                state["streaming_chunks"] = []

            start_time = time.time()
            user_input = state["messages"][0].content
            if not user_input:
                raise Exception("æ— æ³•è·å–ç”¨æˆ·è¾“å…¥")
            state["user_task"] = user_input
            messages = [HumanMessage(content=planning_prompt.format(user_task=user_input))]
            response = self.strategic_llm.invoke(messages)

            plan_data = json_utils.json_match(response.content)
            if not plan_data or not plan_data.get("execution_plan"):
                raise Exception("è®¡åˆ’è§£æå¤±è´¥")

            state["task_analysis"] = plan_data.get("task_analysis", "")
            state["execution_plan"] = plan_data.get("execution_plan", [])
            state["current_step"] = 0

            state["timing_info"] = self._get_timing_info(start_time, "plan_creation")

            self._add_streaming_chunk(state, "plan", "ğŸ“‹ åˆ¶å®šæ‰§è¡Œè®¡åˆ’", {
                "task_analysis": state["task_analysis"],
                "execution_plan": state["execution_plan"]
            })
            return state
        except Exception as e:
            log_error(self.logger, e)
            state["error"] = str(e)
            state["status"] = "failed"
            return state

    def _check_and_execute_node(self, state: PlanExecutorState) -> PlanExecutorState:
        """æ‰§è¡Œå½“å‰èŠ‚ç‚¹"""
        execution_plan = state.get("execution_plan")
        current_step = state.get("current_step")

        if current_step >= len(execution_plan):
            self.logger.info("æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ")
            state["status"] = "completed"
            return state

        current_node = execution_plan[current_step]
        self.check_node(current_node, current_step, execution_plan)

        node_result = self._do_execute(current_node, current_step)

        state["step_results"].append(node_result)
        state["current_step"] += 1

        return self.process_result(current_step + 1, node_result, state)

    def process_result(self, current_step, node_result, state):
        """å¤„ç†æ‰§è¡Œç»“æœ"""
        if node_result.get('status') == 'failed':
            state["status"] = "failed"
            state["error"] = f"èŠ‚ç‚¹ {current_step} æ‰§è¡Œå¤±è´¥: {node_result.get('execution_result', '')}"

            self._add_streaming_chunk(
                state,
                "execution_failed",
                f"âŒ èŠ‚ç‚¹ {current_step} æ‰§è¡Œå¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ",
                {"error": state["error"]}
            )
            return state

        timing = node_result.get("timing")
        self._add_streaming_chunk(
            state,
            "node_completed",
            f"âœ… èŠ‚ç‚¹ {current_step} æ‰§è¡Œå®Œæˆï¼",
            {
                "status": "completed",
                "result": node_result,
                "step_number": current_step,
                "execution_result": node_result.get("execution_result"),
                "timing": timing
            }
        )
        return state

    def check_node(self, current_node, current_step, execution_plan):
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦éœ€è¦è¡¥å……ä¿¡æ¯"""
        if current_node.get("requires_confirmation"):
            self.logger.info(f"èŠ‚ç‚¹ {current_step + 1} éœ€è¦ç”¨æˆ·ç¡®è®¤")

            # å‡†å¤‡ç¡®è®¤ä¿¡æ¯å¹¶ä¸­æ–­
            confirmation_info = {
                "type": "confirmation_required",
                "current_step": current_step + 1,
                "total_steps": len(execution_plan),
                "step_info": {
                    "step": current_node.get("step"),
                    "description": current_node.get("description"),
                    "uncertainty_reason": current_node.get("uncertainty_reason"),
                    "expected_result": current_node.get("expected_result")
                }
            }
            # ä¸­æ–­ç­‰å¾…ç”¨æˆ·è¾“å…¥
            current_node["user_feedback"] = interrupt(confirmation_info)

    def _after_check_and_execute(self, state: PlanExecutorState) -> str:
        """æ£€æŸ¥å¹¶æ‰§è¡ŒèŠ‚ç‚¹åçš„æ¡ä»¶åˆ¤æ–­"""
        status = state.get("status")
        if status == "completed":
            return "complete"  # æ‰€æœ‰èŠ‚ç‚¹å®Œæˆï¼Œè½¬åˆ°ç”Ÿæˆå›å¤
        elif status == "failed":
            return "complete"  # å¤±è´¥ä¹Ÿç»“æŸæµç¨‹
        else:
            return "next_node"  # ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªèŠ‚ç‚¹

    def _do_execute(self, node: Dict[str, Any], node_index: int) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹"""
        start_time = time.time()

        memory_tools = [
            create_manage_memory_tool(namespace=("execute_memories",)),
            create_search_memory_tool(namespace=("execute_memories",)), ]

        try:
            # åˆ›å»ºReAct Agent
            agent = create_react_agent(
                model=self.fast_llm,
                tools=self.all_tools + memory_tools,
                checkpointer=self.checkpointer,
                store=self.store
            )

            # æ ¼å¼åŒ–å·¥å…·åˆ—è¡¨
            tools_list = self._format_tools_list(self.all_tools)

            prompt = react_prompt.format(
                description=node.get("description"),
                expected_result=node.get("expected_result"),
                user_feedback=node.get("user_feedback"),
                tools="\n".join(tools_list)
            )
            try:
                result = agent.invoke(
                    {"messages": [{"role": "user", "content": prompt}]},
                    config=RunnableConfig(configurable={"thread_id": self.thread_id})
                )
            except Exception as agent_error:
                self.logger.warning(f"ReAct Agent æ‰§è¡Œå¤±è´¥ï¼Œä½¿ç”¨ç›´æ¥ LLM è°ƒç”¨: {str(agent_error)}")
                result = self.fast_llm.invoke([HumanMessage(content=prompt)])

            timing_info = self._get_timing_info(start_time, "node_execution")
            return {
                "step": node_index + 1,
                "execution_result": self._extract_execution_result(result, node.get("description")),
                "status": "completed",
                "timing": timing_info
            }
        except Exception as e:
            timing_info = self._get_timing_info(start_time, "node_execution")
            return {
                "step": node_index + 1,
                "execution_result": f"{str(e)}",
                "status": "failed",
                "timing": timing_info
            }

    def _generate_response(self, state: PlanExecutorState) -> PlanExecutorState:
        """ç”Ÿæˆæœ€ç»ˆå›å¤"""
        try:
            task_analysis = state.get("task_analysis")
            execution_plan = state.get("execution_plan")
            step_results = state.get("step_results")
            start_time = time.time()

            # æ ¼å¼åŒ–æ‰§è¡Œè®¡åˆ’
            plan_text = ""
            if execution_plan:
                for i, step in enumerate(execution_plan, 1):
                    plan_text += f"æ­¥éª¤{i}: {step.get('description')}\n"

            # æ ¼å¼åŒ–æ‰§è¡Œç»“æœ
            results_text = ""
            if step_results:
                for i, result in enumerate(step_results, 1):
                    results_text += f"æ­¥éª¤{i}:{result.get('execution_result')}\n"
            try:
                # æ„å»ºæ€»ç»“æç¤º
                summary_messages = [
                    HumanMessage(content=summary_response_prompt.format(
                        user_task=state.get("user_task"),
                        task_analysis=task_analysis,
                        execution_plan=plan_text,
                        step_results=results_text
                    ))
                ]

                response = self.strategic_llm.invoke(summary_messages)
                final_result = response.content.strip()

                state["status"] = "completed"
            except Exception as e:
                self.logger.error(f"LLMæ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
                raise e

            if "timing_info" not in state:
                state["timing_info"] = {}
            response_timing = self._get_timing_info(start_time, "response_generation")
            state["timing_info"].update(response_timing)

            # è®¡ç®—æ€»æ—¶é—´
            total_duration = (
                    state["timing_info"].get("plan_creation_duration", 0) +
                    state["timing_info"].get("response_generation_duration", 0)
            )

            state["streaming_chunks"].append({
                "step": "completed",
                "message": f"ğŸ‰ ä»»åŠ¡å®Œæˆï¼æ€»è€—æ—¶: {total_duration:.2f}ç§’",
                "data": {
                    "response": final_result,
                    "timing_info": state["timing_info"],
                    "total_nodes": len(state.get("execution_plan", [])),
                    "completed_nodes": len(state.get("step_results", [])),
                    "step_results": state.get("step_results", []),
                    "execution_plan": state.get("execution_plan", [])
                }
            })

            self.logger.info(f"å›å¤ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
            return state
        except Exception as e:
            log_error(self.logger, e, "å›å¤ç”Ÿæˆå¤±è´¥")
            state["error"] = str(e)
            state["status"] = "failed"
            return state

    async def chat_with_planning_stream(self, thread_id: str, messages: List = None) -> AsyncIterator[Dict[str, Any]]:
        """æµå¼èŠå¤©æ¥å£ - æ”¯æŒè§„åˆ’æ‰§è¡Œæ¨¡å¼"""
        # åˆå§‹åŒ–çŠ¶æ€
        self.thread_id = thread_id
        initial_state = {
            "messages": messages,
            "task_analysis": "",
            "execution_plan": [],
            "current_step": 0,
            "step_results": [],
            "status": "running",
            "error": "",
            "streaming_chunks": [],
            "timing_info": {},
        }

        config = RunnableConfig(configurable={"thread_id": self.thread_id})
        events = self.graph.astream_events(initial_state, config=config)

        async for chunk in self.process_streaming_events(events):
            yield chunk